# GeoChatAI - Geospatial Image Captioning

GeoChatAI is a web application that leverages the [ChatEarthNet](https://github.com/zhu-xlab/ChatEarthNet) dataset, which contains Sentinel-2 satellite imagery. This application utilizes the dataset to train an open-source CLIP model. It provides a web interface for users to work with images, generating captions and insights based on image analysis.

## Overview

- **Dataset Source:** ChatEarthNet (Sentinel-2 satellite imagery)
- **Dataset Size:**
  - 163,488 image-text pairs with captions generated by ChatGPT-3.5
  - Additional 10,000 image-text pairs with captions generated by ChatGPT-4V
- **Bands Used:** RGB (4-3-2) for general visualization, land cover mapping, and feature identification (e.g., water bodies, urban areas, vegetation)
- **Land Cover Data:** Integrated with ESA's WorldCover Map for accurate land classification
- **Applications:** Fine-tuning large language models (LLMs) for geospatial intelligence and providing AI-generated insights for remote sensing applications.

## Dataset Composition

### Spectral Bands Utilized

Sentinel-2 satellites have 13 spectral bands covering different parts of the electromagnetic spectrum:

1. Band 1 - Coastal aerosol (443 nm)
2. Band 2 - Blue (490 nm)
3. Band 3 - Green (560 nm)
4. Band 4 - Red (665 nm)
5. Band 5 - Vegetation Red Edge (705 nm)
6. Band 6 - Vegetation Red Edge (740 nm)
7. Band 7 - Vegetation Red Edge (783 nm)
8. Band 8 - Near Infrared (842 nm)
9. Band 8A - Narrow Near Infrared (865 nm)
10. Band 9 - Water vapor (945 nm)
11. Band 10 - Short-wave infrared (1375 nm)
12. Band 11 - Short-wave infrared (1610 nm)
13. Band 12 - Short-wave infrared (2190 nm)

### JSON Caption Mapping Files

- Three separate JSON files for **training**, **validation**, and **testing**, each mapping images to textual descriptions.
- The **4V JSON data** mapping corresponds to images from the RGB band dataset.

## Caption Generation Process

- **ChatGPT-3.5**: Used for generating descriptions for the full dataset (163,488 image-text pairs)
- **ChatGPT-4V**: Applied to a subset of **10,000 images** for more detailed multimodal descriptions

## Model and Processing Capabilities

- **CLIP Model:** Trained using ChatEarthNet dataset to generate AI-powered image insights.
- **ChatGPT-4V:** Processes **500 images per day** (Multimodal - accepts visual inputs)
- **ChatGPT-3.5:** Handles **10,000 images per day** (Text-only representation of images)

## Sentinel-2 and World Cover Integration

Sentinel-2 is part of the **Copernicus Program** by the **European Space Agency (ESA)**, consisting of Sentinel-2A and Sentinel-2B satellites. These satellites provide high-resolution imagery with open access for various applications:

- **Agriculture**
- **Forestry**
- **Environmental Monitoring**
- **Natural Disaster Management**

### World Cover Map

The **World Cover Map**, developed by ESA, utilizes data from both Sentinel-1 and Sentinel-2 to produce high-resolution global land cover maps. A **Gradient Boosting Decision Tree model (CatBoost)** is trained on these features to classify pixels into **11 land cover classes**.

## GeoChatAI Web Interface

GeoChatAI provides a user-friendly web interface where users can:
- Upload satellite images for AI-based caption generation.
- Extract insights from remote sensing data.
- Interact with AI-generated descriptions for better geospatial analysis.

## Future Considerations

- Additional fine-tuning of the CLIP model with larger datasets.
- Enhancing real-time image processing capabilities.
- Expanding AI insights beyond caption generation to include land classification and anomaly detection.

## Conclusion

GeoChatAI bridges the gap between AI and geospatial intelligence by utilizing the ChatEarthNet dataset to train an open-source CLIP model. This web-based tool empowers users with AI-generated image insights, making satellite imagery analysis accessible to non-experts and professionals alike.

